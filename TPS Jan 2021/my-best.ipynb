{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\nfrom tqdm import tqdm","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas  as pd\nimport xgboost as xgb\n\n#===========================================================================\n# read in the data\n# Original kernel: https://www.kaggle.com/carlmcbrideellis/very-simple-xgboost-regression\n#===========================================================================\ntrain_data = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')\ntest_data  = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')\n\n#===========================================================================\n# select some features of interest (\"ay, there's the rub\", Shakespeare)\n#===========================================================================\nfeatures = ['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7',\n       'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14']\n\n#===========================================================================\n#===========================================================================\nX_train = train_data[features]\ny_train = train_data[\"target\"]\nfinal_X_test = test_data[features]\n\n#===========================================================================\n# XGBoost regression: \n# Parameters: \n# n_estimators  \"Number of gradient boosted trees. Equivalent to number \n#                of boosting rounds.\"\n# learning_rate \"Boosting learning rate (xgb’s “eta”)\"\n# max_depth     \"Maximum depth of a tree. Increasing this value will make \n#                the model more complex and more likely to overfit.\" \n#===========================================================================\n# regressor=xgb.XGBRegressor(n_estimators  = 500,\n#                            learning_rate = 0.1,\n#                            max_depth     = 5)\n# regressor.fit(X_train, y_train)\n\n#===========================================================================\n# To use early_stopping_rounds: \n# \"Validation metric needs to improve at least once in every \n# early_stopping_rounds round(s) to continue training.\"\n#===========================================================================\n# perform a test/train split \nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n\n# params for XGB are taked from this great kernel https://www.kaggle.com/hamzaghanmi/xgboost-hyperparameter-tuning-using-optuna \n# by Hamza Ghanmi\n\nregressor = xgb.XGBRegressor(\n                 colsample_bytree=0.5,\n                 alpha=0.01563,\n                 #gamma=0.0,\n                 learning_rate=0.01,\n                 max_depth=15,\n                 min_child_weight=257,\n                 n_estimators=4000,                                                                  \n                 #reg_alpha=0.9,\n                 reg_lambda=0.003,\n                 subsample=0.7,\n                 random_state=2020,\n                 metric_period=100,\n                 silent=0)#silent 1にするとwarningがでてくる\n\nregressor.fit(X_train, y_train, early_stopping_rounds=6, eval_set=[(X_test, y_test)], verbose=0)","execution_count":2,"outputs":[{"output_type":"stream","text":"[03:37:12] WARNING: ../src/learner.cc:541: \nParameters: { metric_period, silent } might not be used.\n\n  This may not be accurate due to some parameters are only used in language bindings but\n  passed down to XGBoost core.  Or some parameters are not used but slip through this\n  verification. Please open an issue if you find above cases.\n\n\n[0]\tvalidation_0-rmse:7.37014\n[1]\tvalidation_0-rmse:7.29718\n[2]\tvalidation_0-rmse:7.22493\n[3]\tvalidation_0-rmse:7.15340\n[4]\tvalidation_0-rmse:7.08261\n[5]\tvalidation_0-rmse:7.01254\n[6]\tvalidation_0-rmse:6.94320\n[7]\tvalidation_0-rmse:6.87452\n[8]\tvalidation_0-rmse:6.80658\n[9]\tvalidation_0-rmse:6.73929\n[10]\tvalidation_0-rmse:6.67271\n[11]\tvalidation_0-rmse:6.60677\n[12]\tvalidation_0-rmse:6.54150\n[13]\tvalidation_0-rmse:6.47690\n[14]\tvalidation_0-rmse:6.41297\n[15]\tvalidation_0-rmse:6.34965\n[16]\tvalidation_0-rmse:6.28699\n[17]\tvalidation_0-rmse:6.22495\n[18]\tvalidation_0-rmse:6.16354\n[19]\tvalidation_0-rmse:6.10277\n[20]\tvalidation_0-rmse:6.04260\n[21]\tvalidation_0-rmse:5.98306\n[22]\tvalidation_0-rmse:5.92411\n[23]\tvalidation_0-rmse:5.86576\n[24]\tvalidation_0-rmse:5.80801\n[25]\tvalidation_0-rmse:5.75085\n[26]\tvalidation_0-rmse:5.69427\n[27]\tvalidation_0-rmse:5.63825\n[28]\tvalidation_0-rmse:5.58281\n[29]\tvalidation_0-rmse:5.52794\n[30]\tvalidation_0-rmse:5.47360\n[31]\tvalidation_0-rmse:5.41983\n[32]\tvalidation_0-rmse:5.36662\n[33]\tvalidation_0-rmse:5.31393\n[34]\tvalidation_0-rmse:5.26180\n[35]\tvalidation_0-rmse:5.21021\n[36]\tvalidation_0-rmse:5.15911\n[37]\tvalidation_0-rmse:5.10853\n[38]\tvalidation_0-rmse:5.05847\n[39]\tvalidation_0-rmse:5.00893\n[40]\tvalidation_0-rmse:4.95988\n[41]\tvalidation_0-rmse:4.91134\n[42]\tvalidation_0-rmse:4.86329\n[43]\tvalidation_0-rmse:4.81574\n[44]\tvalidation_0-rmse:4.76865\n[45]\tvalidation_0-rmse:4.72206\n[46]\tvalidation_0-rmse:4.67594\n[47]\tvalidation_0-rmse:4.63030\n[48]\tvalidation_0-rmse:4.58513\n[49]\tvalidation_0-rmse:4.54040\n[50]\tvalidation_0-rmse:4.49613\n[51]\tvalidation_0-rmse:4.45234\n[52]\tvalidation_0-rmse:4.40898\n[53]\tvalidation_0-rmse:4.36606\n[54]\tvalidation_0-rmse:4.32359\n[55]\tvalidation_0-rmse:4.28157\n[56]\tvalidation_0-rmse:4.23999\n[57]\tvalidation_0-rmse:4.19881\n[58]\tvalidation_0-rmse:4.15807\n[59]\tvalidation_0-rmse:4.11771\n[60]\tvalidation_0-rmse:4.07782\n[61]\tvalidation_0-rmse:4.03832\n[62]\tvalidation_0-rmse:3.99920\n[63]\tvalidation_0-rmse:3.96051\n[64]\tvalidation_0-rmse:3.92220\n[65]\tvalidation_0-rmse:3.88430\n[66]\tvalidation_0-rmse:3.84679\n[67]\tvalidation_0-rmse:3.80969\n[68]\tvalidation_0-rmse:3.77293\n[69]\tvalidation_0-rmse:3.73659\n[70]\tvalidation_0-rmse:3.70062\n[71]\tvalidation_0-rmse:3.66501\n[72]\tvalidation_0-rmse:3.62978\n[73]\tvalidation_0-rmse:3.59489\n[74]\tvalidation_0-rmse:3.56040\n[75]\tvalidation_0-rmse:3.52625\n[76]\tvalidation_0-rmse:3.49246\n[77]\tvalidation_0-rmse:3.45902\n[78]\tvalidation_0-rmse:3.42592\n[79]\tvalidation_0-rmse:3.39316\n[80]\tvalidation_0-rmse:3.36075\n[81]\tvalidation_0-rmse:3.32866\n[82]\tvalidation_0-rmse:3.29691\n[83]\tvalidation_0-rmse:3.26551\n[84]\tvalidation_0-rmse:3.23444\n[85]\tvalidation_0-rmse:3.20368\n[86]\tvalidation_0-rmse:3.17324\n[87]\tvalidation_0-rmse:3.14313\n[88]\tvalidation_0-rmse:3.11333\n[89]\tvalidation_0-rmse:3.08383\n[90]\tvalidation_0-rmse:3.05467\n[91]\tvalidation_0-rmse:3.02579\n[92]\tvalidation_0-rmse:2.99722\n[93]\tvalidation_0-rmse:2.96896\n[94]\tvalidation_0-rmse:2.94098\n[95]\tvalidation_0-rmse:2.91330\n[96]\tvalidation_0-rmse:2.88591\n[97]\tvalidation_0-rmse:2.85880\n[98]\tvalidation_0-rmse:2.83199\n[99]\tvalidation_0-rmse:2.80547\n[100]\tvalidation_0-rmse:2.77923\n[101]\tvalidation_0-rmse:2.75327\n[102]\tvalidation_0-rmse:2.72759\n[103]\tvalidation_0-rmse:2.70217\n[104]\tvalidation_0-rmse:2.67704\n[105]\tvalidation_0-rmse:2.65216\n[106]\tvalidation_0-rmse:2.62755\n[107]\tvalidation_0-rmse:2.60323\n[108]\tvalidation_0-rmse:2.57917\n[109]\tvalidation_0-rmse:2.55536\n[110]\tvalidation_0-rmse:2.53180\n[111]\tvalidation_0-rmse:2.50850\n[112]\tvalidation_0-rmse:2.48544\n[113]\tvalidation_0-rmse:2.46264\n[114]\tvalidation_0-rmse:2.44006\n[115]\tvalidation_0-rmse:2.41773\n[116]\tvalidation_0-rmse:2.39566\n[117]\tvalidation_0-rmse:2.37381\n[118]\tvalidation_0-rmse:2.35222\n[119]\tvalidation_0-rmse:2.33086\n[120]\tvalidation_0-rmse:2.30970\n[121]\tvalidation_0-rmse:2.28878\n[122]\tvalidation_0-rmse:2.26811\n[123]\tvalidation_0-rmse:2.24767\n[124]\tvalidation_0-rmse:2.22744\n[125]\tvalidation_0-rmse:2.20744\n[126]\tvalidation_0-rmse:2.18765\n[127]\tvalidation_0-rmse:2.16807\n[128]\tvalidation_0-rmse:2.14873\n[129]\tvalidation_0-rmse:2.12958\n[130]\tvalidation_0-rmse:2.11066\n[131]\tvalidation_0-rmse:2.09196\n[132]\tvalidation_0-rmse:2.07346\n[133]\tvalidation_0-rmse:2.05515\n[134]\tvalidation_0-rmse:2.03706\n[135]\tvalidation_0-rmse:2.01918\n[136]\tvalidation_0-rmse:2.00150\n[137]\tvalidation_0-rmse:1.98400\n[138]\tvalidation_0-rmse:1.96670\n[139]\tvalidation_0-rmse:1.94962\n[140]\tvalidation_0-rmse:1.93269\n[141]\tvalidation_0-rmse:1.91598\n[142]\tvalidation_0-rmse:1.89945\n[143]\tvalidation_0-rmse:1.88312\n[144]\tvalidation_0-rmse:1.86696\n[145]\tvalidation_0-rmse:1.85099\n[146]\tvalidation_0-rmse:1.83519\n[147]\tvalidation_0-rmse:1.81958\n[148]\tvalidation_0-rmse:1.80415\n[149]\tvalidation_0-rmse:1.78889\n[150]\tvalidation_0-rmse:1.77382\n[151]\tvalidation_0-rmse:1.75893\n[152]\tvalidation_0-rmse:1.74420\n[153]\tvalidation_0-rmse:1.72963\n[154]\tvalidation_0-rmse:1.71524\n[155]\tvalidation_0-rmse:1.70100\n[156]\tvalidation_0-rmse:1.68691\n[157]\tvalidation_0-rmse:1.67303\n[158]\tvalidation_0-rmse:1.65930\n[159]\tvalidation_0-rmse:1.64573\n[160]\tvalidation_0-rmse:1.63231\n[161]\tvalidation_0-rmse:1.61906\n[162]\tvalidation_0-rmse:1.60596\n[163]\tvalidation_0-rmse:1.59301\n[164]\tvalidation_0-rmse:1.58022\n[165]\tvalidation_0-rmse:1.56759\n[166]\tvalidation_0-rmse:1.55509\n[167]\tvalidation_0-rmse:1.54276\n[168]\tvalidation_0-rmse:1.53058\n[169]\tvalidation_0-rmse:1.51854\n[170]\tvalidation_0-rmse:1.50662\n[171]\tvalidation_0-rmse:1.49485\n[172]\tvalidation_0-rmse:1.48325\n[173]\tvalidation_0-rmse:1.47180\n[174]\tvalidation_0-rmse:1.46046\n[175]\tvalidation_0-rmse:1.44928\n[176]\tvalidation_0-rmse:1.43824\n[177]\tvalidation_0-rmse:1.42733\n[178]\tvalidation_0-rmse:1.41654\n[179]\tvalidation_0-rmse:1.40591\n[180]\tvalidation_0-rmse:1.39539\n[181]\tvalidation_0-rmse:1.38501\n[182]\tvalidation_0-rmse:1.37477\n[183]\tvalidation_0-rmse:1.36465\n[184]\tvalidation_0-rmse:1.35465\n[185]\tvalidation_0-rmse:1.34478\n[186]\tvalidation_0-rmse:1.33505\n[187]\tvalidation_0-rmse:1.32542\n[188]\tvalidation_0-rmse:1.31593\n[189]\tvalidation_0-rmse:1.30656\n[190]\tvalidation_0-rmse:1.29730\n[191]\tvalidation_0-rmse:1.28817\n[192]\tvalidation_0-rmse:1.27917\n[193]\tvalidation_0-rmse:1.27028\n[194]\tvalidation_0-rmse:1.26149\n[195]\tvalidation_0-rmse:1.25282\n[196]\tvalidation_0-rmse:1.24426\n[197]\tvalidation_0-rmse:1.23582\n[198]\tvalidation_0-rmse:1.22747\n[199]\tvalidation_0-rmse:1.21926\n[200]\tvalidation_0-rmse:1.21115\n[201]\tvalidation_0-rmse:1.20316\n[202]\tvalidation_0-rmse:1.19526\n[203]\tvalidation_0-rmse:1.18747\n[204]\tvalidation_0-rmse:1.17978\n[205]\tvalidation_0-rmse:1.17219\n[206]\tvalidation_0-rmse:1.16470\n[207]\tvalidation_0-rmse:1.15732\n[208]\tvalidation_0-rmse:1.15004\n[209]\tvalidation_0-rmse:1.14286\n[210]\tvalidation_0-rmse:1.13578\n[211]\tvalidation_0-rmse:1.12878\n[212]\tvalidation_0-rmse:1.12187\n[213]\tvalidation_0-rmse:1.11507\n[214]\tvalidation_0-rmse:1.10839\n[215]\tvalidation_0-rmse:1.10179\n[216]\tvalidation_0-rmse:1.09526\n[217]\tvalidation_0-rmse:1.08884\n[218]\tvalidation_0-rmse:1.08250\n[219]\tvalidation_0-rmse:1.07625\n[220]\tvalidation_0-rmse:1.07009\n[221]\tvalidation_0-rmse:1.06402\n[222]\tvalidation_0-rmse:1.05805\n[223]\tvalidation_0-rmse:1.05214\n[224]\tvalidation_0-rmse:1.04632\n[225]\tvalidation_0-rmse:1.04058\n[226]\tvalidation_0-rmse:1.03492\n[227]\tvalidation_0-rmse:1.02933\n[228]\tvalidation_0-rmse:1.02385\n[229]\tvalidation_0-rmse:1.01843\n[230]\tvalidation_0-rmse:1.01310\n[231]\tvalidation_0-rmse:1.00785\n[232]\tvalidation_0-rmse:1.00267\n[233]\tvalidation_0-rmse:0.99757\n[234]\tvalidation_0-rmse:0.99255\n[235]\tvalidation_0-rmse:0.98761\n[236]\tvalidation_0-rmse:0.98272\n[237]\tvalidation_0-rmse:0.97792\n[238]\tvalidation_0-rmse:0.97320\n[239]\tvalidation_0-rmse:0.96854\n[240]\tvalidation_0-rmse:0.96396\n[241]\tvalidation_0-rmse:0.95944\n[242]\tvalidation_0-rmse:0.95500\n[243]\tvalidation_0-rmse:0.95061\n[244]\tvalidation_0-rmse:0.94629\n[245]\tvalidation_0-rmse:0.94205\n[246]\tvalidation_0-rmse:0.93788\n[247]\tvalidation_0-rmse:0.93375\n[248]\tvalidation_0-rmse:0.92968\n","name":"stdout"},{"output_type":"stream","text":"[249]\tvalidation_0-rmse:0.92568\n[250]\tvalidation_0-rmse:0.92174\n[251]\tvalidation_0-rmse:0.91788\n[252]\tvalidation_0-rmse:0.91405\n[253]\tvalidation_0-rmse:0.91030\n[254]\tvalidation_0-rmse:0.90661\n[255]\tvalidation_0-rmse:0.90299\n[256]\tvalidation_0-rmse:0.89942\n[257]\tvalidation_0-rmse:0.89591\n[258]\tvalidation_0-rmse:0.89246\n[259]\tvalidation_0-rmse:0.88905\n[260]\tvalidation_0-rmse:0.88570\n[261]\tvalidation_0-rmse:0.88241\n[262]\tvalidation_0-rmse:0.87918\n[263]\tvalidation_0-rmse:0.87599\n[264]\tvalidation_0-rmse:0.87287\n[265]\tvalidation_0-rmse:0.86979\n[266]\tvalidation_0-rmse:0.86675\n[267]\tvalidation_0-rmse:0.86376\n[268]\tvalidation_0-rmse:0.86082\n[269]\tvalidation_0-rmse:0.85793\n[270]\tvalidation_0-rmse:0.85509\n[271]\tvalidation_0-rmse:0.85229\n[272]\tvalidation_0-rmse:0.84955\n[273]\tvalidation_0-rmse:0.84685\n[274]\tvalidation_0-rmse:0.84419\n[275]\tvalidation_0-rmse:0.84157\n[276]\tvalidation_0-rmse:0.83901\n[277]\tvalidation_0-rmse:0.83649\n[278]\tvalidation_0-rmse:0.83400\n[279]\tvalidation_0-rmse:0.83156\n[280]\tvalidation_0-rmse:0.82916\n[281]\tvalidation_0-rmse:0.82680\n[282]\tvalidation_0-rmse:0.82449\n[283]\tvalidation_0-rmse:0.82220\n[284]\tvalidation_0-rmse:0.81996\n[285]\tvalidation_0-rmse:0.81775\n[286]\tvalidation_0-rmse:0.81558\n[287]\tvalidation_0-rmse:0.81344\n[288]\tvalidation_0-rmse:0.81135\n[289]\tvalidation_0-rmse:0.80929\n[290]\tvalidation_0-rmse:0.80727\n[291]\tvalidation_0-rmse:0.80529\n[292]\tvalidation_0-rmse:0.80333\n[293]\tvalidation_0-rmse:0.80141\n[294]\tvalidation_0-rmse:0.79951\n[295]\tvalidation_0-rmse:0.79765\n[296]\tvalidation_0-rmse:0.79582\n[297]\tvalidation_0-rmse:0.79403\n[298]\tvalidation_0-rmse:0.79228\n[299]\tvalidation_0-rmse:0.79055\n[300]\tvalidation_0-rmse:0.78885\n[301]\tvalidation_0-rmse:0.78718\n[302]\tvalidation_0-rmse:0.78553\n[303]\tvalidation_0-rmse:0.78392\n[304]\tvalidation_0-rmse:0.78234\n[305]\tvalidation_0-rmse:0.78078\n[306]\tvalidation_0-rmse:0.77926\n[307]\tvalidation_0-rmse:0.77776\n[308]\tvalidation_0-rmse:0.77630\n[309]\tvalidation_0-rmse:0.77485\n[310]\tvalidation_0-rmse:0.77344\n[311]\tvalidation_0-rmse:0.77205\n[312]\tvalidation_0-rmse:0.77067\n[313]\tvalidation_0-rmse:0.76933\n[314]\tvalidation_0-rmse:0.76802\n[315]\tvalidation_0-rmse:0.76672\n[316]\tvalidation_0-rmse:0.76543\n[317]\tvalidation_0-rmse:0.76419\n[318]\tvalidation_0-rmse:0.76296\n[319]\tvalidation_0-rmse:0.76175\n[320]\tvalidation_0-rmse:0.76056\n[321]\tvalidation_0-rmse:0.75940\n[322]\tvalidation_0-rmse:0.75825\n[323]\tvalidation_0-rmse:0.75713\n[324]\tvalidation_0-rmse:0.75603\n[325]\tvalidation_0-rmse:0.75495\n[326]\tvalidation_0-rmse:0.75389\n[327]\tvalidation_0-rmse:0.75285\n[328]\tvalidation_0-rmse:0.75182\n[329]\tvalidation_0-rmse:0.75080\n[330]\tvalidation_0-rmse:0.74981\n[331]\tvalidation_0-rmse:0.74884\n[332]\tvalidation_0-rmse:0.74787\n[333]\tvalidation_0-rmse:0.74693\n[334]\tvalidation_0-rmse:0.74602\n[335]\tvalidation_0-rmse:0.74512\n[336]\tvalidation_0-rmse:0.74424\n[337]\tvalidation_0-rmse:0.74338\n[338]\tvalidation_0-rmse:0.74252\n[339]\tvalidation_0-rmse:0.74168\n[340]\tvalidation_0-rmse:0.74086\n[341]\tvalidation_0-rmse:0.74005\n[342]\tvalidation_0-rmse:0.73927\n[343]\tvalidation_0-rmse:0.73849\n[344]\tvalidation_0-rmse:0.73772\n[345]\tvalidation_0-rmse:0.73698\n[346]\tvalidation_0-rmse:0.73624\n[347]\tvalidation_0-rmse:0.73551\n[348]\tvalidation_0-rmse:0.73481\n[349]\tvalidation_0-rmse:0.73412\n[350]\tvalidation_0-rmse:0.73343\n[351]\tvalidation_0-rmse:0.73276\n[352]\tvalidation_0-rmse:0.73211\n[353]\tvalidation_0-rmse:0.73146\n[354]\tvalidation_0-rmse:0.73083\n[355]\tvalidation_0-rmse:0.73020\n[356]\tvalidation_0-rmse:0.72959\n[357]\tvalidation_0-rmse:0.72899\n[358]\tvalidation_0-rmse:0.72840\n[359]\tvalidation_0-rmse:0.72782\n[360]\tvalidation_0-rmse:0.72725\n[361]\tvalidation_0-rmse:0.72671\n[362]\tvalidation_0-rmse:0.72616\n[363]\tvalidation_0-rmse:0.72562\n[364]\tvalidation_0-rmse:0.72511\n[365]\tvalidation_0-rmse:0.72459\n[366]\tvalidation_0-rmse:0.72408\n[367]\tvalidation_0-rmse:0.72358\n[368]\tvalidation_0-rmse:0.72308\n[369]\tvalidation_0-rmse:0.72261\n[370]\tvalidation_0-rmse:0.72213\n[371]\tvalidation_0-rmse:0.72168\n[372]\tvalidation_0-rmse:0.72123\n[373]\tvalidation_0-rmse:0.72078\n[374]\tvalidation_0-rmse:0.72036\n[375]\tvalidation_0-rmse:0.71992\n[376]\tvalidation_0-rmse:0.71950\n[377]\tvalidation_0-rmse:0.71909\n[378]\tvalidation_0-rmse:0.71869\n[379]\tvalidation_0-rmse:0.71829\n[380]\tvalidation_0-rmse:0.71791\n[381]\tvalidation_0-rmse:0.71753\n[382]\tvalidation_0-rmse:0.71715\n[383]\tvalidation_0-rmse:0.71679\n[384]\tvalidation_0-rmse:0.71643\n[385]\tvalidation_0-rmse:0.71607\n[386]\tvalidation_0-rmse:0.71573\n[387]\tvalidation_0-rmse:0.71540\n[388]\tvalidation_0-rmse:0.71506\n[389]\tvalidation_0-rmse:0.71473\n[390]\tvalidation_0-rmse:0.71439\n[391]\tvalidation_0-rmse:0.71408\n[392]\tvalidation_0-rmse:0.71378\n[393]\tvalidation_0-rmse:0.71347\n[394]\tvalidation_0-rmse:0.71317\n[395]\tvalidation_0-rmse:0.71288\n[396]\tvalidation_0-rmse:0.71260\n[397]\tvalidation_0-rmse:0.71232\n[398]\tvalidation_0-rmse:0.71204\n[399]\tvalidation_0-rmse:0.71178\n[400]\tvalidation_0-rmse:0.71151\n[401]\tvalidation_0-rmse:0.71124\n[402]\tvalidation_0-rmse:0.71098\n[403]\tvalidation_0-rmse:0.71073\n[404]\tvalidation_0-rmse:0.71049\n[405]\tvalidation_0-rmse:0.71025\n[406]\tvalidation_0-rmse:0.71000\n[407]\tvalidation_0-rmse:0.70977\n[408]\tvalidation_0-rmse:0.70955\n[409]\tvalidation_0-rmse:0.70932\n[410]\tvalidation_0-rmse:0.70910\n[411]\tvalidation_0-rmse:0.70887\n[412]\tvalidation_0-rmse:0.70866\n[413]\tvalidation_0-rmse:0.70844\n[414]\tvalidation_0-rmse:0.70824\n[415]\tvalidation_0-rmse:0.70804\n[416]\tvalidation_0-rmse:0.70784\n[417]\tvalidation_0-rmse:0.70764\n[418]\tvalidation_0-rmse:0.70746\n[419]\tvalidation_0-rmse:0.70727\n[420]\tvalidation_0-rmse:0.70708\n[421]\tvalidation_0-rmse:0.70691\n[422]\tvalidation_0-rmse:0.70673\n[423]\tvalidation_0-rmse:0.70656\n[424]\tvalidation_0-rmse:0.70638\n[425]\tvalidation_0-rmse:0.70622\n[426]\tvalidation_0-rmse:0.70605\n[427]\tvalidation_0-rmse:0.70590\n[428]\tvalidation_0-rmse:0.70574\n[429]\tvalidation_0-rmse:0.70559\n[430]\tvalidation_0-rmse:0.70544\n[431]\tvalidation_0-rmse:0.70529\n[432]\tvalidation_0-rmse:0.70514\n[433]\tvalidation_0-rmse:0.70500\n[434]\tvalidation_0-rmse:0.70487\n[435]\tvalidation_0-rmse:0.70474\n[436]\tvalidation_0-rmse:0.70460\n[437]\tvalidation_0-rmse:0.70447\n[438]\tvalidation_0-rmse:0.70434\n[439]\tvalidation_0-rmse:0.70421\n[440]\tvalidation_0-rmse:0.70408\n[441]\tvalidation_0-rmse:0.70395\n[442]\tvalidation_0-rmse:0.70384\n[443]\tvalidation_0-rmse:0.70371\n[444]\tvalidation_0-rmse:0.70360\n[445]\tvalidation_0-rmse:0.70348\n[446]\tvalidation_0-rmse:0.70336\n[447]\tvalidation_0-rmse:0.70325\n[448]\tvalidation_0-rmse:0.70313\n[449]\tvalidation_0-rmse:0.70302\n[450]\tvalidation_0-rmse:0.70291\n[451]\tvalidation_0-rmse:0.70281\n[452]\tvalidation_0-rmse:0.70272\n[453]\tvalidation_0-rmse:0.70262\n[454]\tvalidation_0-rmse:0.70252\n[455]\tvalidation_0-rmse:0.70243\n[456]\tvalidation_0-rmse:0.70234\n[457]\tvalidation_0-rmse:0.70224\n[458]\tvalidation_0-rmse:0.70215\n[459]\tvalidation_0-rmse:0.70206\n[460]\tvalidation_0-rmse:0.70197\n[461]\tvalidation_0-rmse:0.70188\n[462]\tvalidation_0-rmse:0.70178\n[463]\tvalidation_0-rmse:0.70170\n[464]\tvalidation_0-rmse:0.70162\n[465]\tvalidation_0-rmse:0.70154\n[466]\tvalidation_0-rmse:0.70146\n[467]\tvalidation_0-rmse:0.70138\n[468]\tvalidation_0-rmse:0.70129\n[469]\tvalidation_0-rmse:0.70121\n[470]\tvalidation_0-rmse:0.70113\n[471]\tvalidation_0-rmse:0.70106\n[472]\tvalidation_0-rmse:0.70099\n[473]\tvalidation_0-rmse:0.70093\n[474]\tvalidation_0-rmse:0.70085\n[475]\tvalidation_0-rmse:0.70078\n[476]\tvalidation_0-rmse:0.70071\n[477]\tvalidation_0-rmse:0.70065\n[478]\tvalidation_0-rmse:0.70058\n[479]\tvalidation_0-rmse:0.70051\n[480]\tvalidation_0-rmse:0.70045\n[481]\tvalidation_0-rmse:0.70039\n[482]\tvalidation_0-rmse:0.70034\n[483]\tvalidation_0-rmse:0.70028\n[484]\tvalidation_0-rmse:0.70022\n[485]\tvalidation_0-rmse:0.70017\n[486]\tvalidation_0-rmse:0.70012\n[487]\tvalidation_0-rmse:0.70007\n[488]\tvalidation_0-rmse:0.70001\n[489]\tvalidation_0-rmse:0.69995\n[490]\tvalidation_0-rmse:0.69990\n[491]\tvalidation_0-rmse:0.69985\n[492]\tvalidation_0-rmse:0.69980\n[493]\tvalidation_0-rmse:0.69974\n[494]\tvalidation_0-rmse:0.69969\n[495]\tvalidation_0-rmse:0.69965\n[496]\tvalidation_0-rmse:0.69960\n[497]\tvalidation_0-rmse:0.69956\n[498]\tvalidation_0-rmse:0.69951\n[499]\tvalidation_0-rmse:0.69947\n[500]\tvalidation_0-rmse:0.69942\n[501]\tvalidation_0-rmse:0.69938\n[502]\tvalidation_0-rmse:0.69933\n[503]\tvalidation_0-rmse:0.69929\n[504]\tvalidation_0-rmse:0.69925\n[505]\tvalidation_0-rmse:0.69921\n","name":"stdout"},{"output_type":"stream","text":"[506]\tvalidation_0-rmse:0.69916\n[507]\tvalidation_0-rmse:0.69912\n[508]\tvalidation_0-rmse:0.69909\n[509]\tvalidation_0-rmse:0.69905\n[510]\tvalidation_0-rmse:0.69902\n[511]\tvalidation_0-rmse:0.69899\n[512]\tvalidation_0-rmse:0.69895\n[513]\tvalidation_0-rmse:0.69891\n[514]\tvalidation_0-rmse:0.69888\n[515]\tvalidation_0-rmse:0.69884\n[516]\tvalidation_0-rmse:0.69881\n[517]\tvalidation_0-rmse:0.69878\n[518]\tvalidation_0-rmse:0.69875\n[519]\tvalidation_0-rmse:0.69872\n[520]\tvalidation_0-rmse:0.69869\n[521]\tvalidation_0-rmse:0.69866\n[522]\tvalidation_0-rmse:0.69863\n[523]\tvalidation_0-rmse:0.69860\n[524]\tvalidation_0-rmse:0.69857\n[525]\tvalidation_0-rmse:0.69854\n[526]\tvalidation_0-rmse:0.69852\n[527]\tvalidation_0-rmse:0.69849\n[528]\tvalidation_0-rmse:0.69846\n[529]\tvalidation_0-rmse:0.69843\n[530]\tvalidation_0-rmse:0.69840\n[531]\tvalidation_0-rmse:0.69838\n[532]\tvalidation_0-rmse:0.69835\n[533]\tvalidation_0-rmse:0.69832\n[534]\tvalidation_0-rmse:0.69829\n[535]\tvalidation_0-rmse:0.69827\n[536]\tvalidation_0-rmse:0.69824\n[537]\tvalidation_0-rmse:0.69822\n[538]\tvalidation_0-rmse:0.69820\n[539]\tvalidation_0-rmse:0.69818\n[540]\tvalidation_0-rmse:0.69816\n[541]\tvalidation_0-rmse:0.69814\n[542]\tvalidation_0-rmse:0.69812\n[543]\tvalidation_0-rmse:0.69809\n[544]\tvalidation_0-rmse:0.69806\n[545]\tvalidation_0-rmse:0.69804\n[546]\tvalidation_0-rmse:0.69801\n[547]\tvalidation_0-rmse:0.69799\n[548]\tvalidation_0-rmse:0.69797\n[549]\tvalidation_0-rmse:0.69795\n[550]\tvalidation_0-rmse:0.69793\n[551]\tvalidation_0-rmse:0.69791\n[552]\tvalidation_0-rmse:0.69789\n[553]\tvalidation_0-rmse:0.69787\n[554]\tvalidation_0-rmse:0.69786\n[555]\tvalidation_0-rmse:0.69785\n[556]\tvalidation_0-rmse:0.69783\n[557]\tvalidation_0-rmse:0.69781\n[558]\tvalidation_0-rmse:0.69780\n[559]\tvalidation_0-rmse:0.69778\n[560]\tvalidation_0-rmse:0.69776\n[561]\tvalidation_0-rmse:0.69774\n[562]\tvalidation_0-rmse:0.69773\n[563]\tvalidation_0-rmse:0.69772\n[564]\tvalidation_0-rmse:0.69770\n[565]\tvalidation_0-rmse:0.69769\n[566]\tvalidation_0-rmse:0.69768\n[567]\tvalidation_0-rmse:0.69766\n[568]\tvalidation_0-rmse:0.69764\n[569]\tvalidation_0-rmse:0.69763\n[570]\tvalidation_0-rmse:0.69761\n[571]\tvalidation_0-rmse:0.69759\n[572]\tvalidation_0-rmse:0.69758\n[573]\tvalidation_0-rmse:0.69756\n[574]\tvalidation_0-rmse:0.69755\n[575]\tvalidation_0-rmse:0.69753\n[576]\tvalidation_0-rmse:0.69751\n[577]\tvalidation_0-rmse:0.69749\n[578]\tvalidation_0-rmse:0.69748\n[579]\tvalidation_0-rmse:0.69746\n[580]\tvalidation_0-rmse:0.69745\n[581]\tvalidation_0-rmse:0.69744\n[582]\tvalidation_0-rmse:0.69742\n[583]\tvalidation_0-rmse:0.69741\n[584]\tvalidation_0-rmse:0.69740\n[585]\tvalidation_0-rmse:0.69738\n[586]\tvalidation_0-rmse:0.69737\n[587]\tvalidation_0-rmse:0.69736\n[588]\tvalidation_0-rmse:0.69735\n[589]\tvalidation_0-rmse:0.69734\n[590]\tvalidation_0-rmse:0.69733\n[591]\tvalidation_0-rmse:0.69732\n[592]\tvalidation_0-rmse:0.69731\n[593]\tvalidation_0-rmse:0.69729\n[594]\tvalidation_0-rmse:0.69728\n[595]\tvalidation_0-rmse:0.69726\n[596]\tvalidation_0-rmse:0.69726\n[597]\tvalidation_0-rmse:0.69725\n[598]\tvalidation_0-rmse:0.69723\n[599]\tvalidation_0-rmse:0.69722\n[600]\tvalidation_0-rmse:0.69721\n[601]\tvalidation_0-rmse:0.69720\n[602]\tvalidation_0-rmse:0.69720\n[603]\tvalidation_0-rmse:0.69719\n[604]\tvalidation_0-rmse:0.69719\n[605]\tvalidation_0-rmse:0.69717\n[606]\tvalidation_0-rmse:0.69716\n[607]\tvalidation_0-rmse:0.69716\n[608]\tvalidation_0-rmse:0.69715\n[609]\tvalidation_0-rmse:0.69714\n[610]\tvalidation_0-rmse:0.69714\n[611]\tvalidation_0-rmse:0.69713\n[612]\tvalidation_0-rmse:0.69712\n[613]\tvalidation_0-rmse:0.69711\n[614]\tvalidation_0-rmse:0.69710\n[615]\tvalidation_0-rmse:0.69709\n[616]\tvalidation_0-rmse:0.69708\n[617]\tvalidation_0-rmse:0.69707\n[618]\tvalidation_0-rmse:0.69707\n[619]\tvalidation_0-rmse:0.69705\n[620]\tvalidation_0-rmse:0.69704\n[621]\tvalidation_0-rmse:0.69703\n[622]\tvalidation_0-rmse:0.69703\n[623]\tvalidation_0-rmse:0.69702\n[624]\tvalidation_0-rmse:0.69701\n[625]\tvalidation_0-rmse:0.69701\n[626]\tvalidation_0-rmse:0.69700\n[627]\tvalidation_0-rmse:0.69699\n[628]\tvalidation_0-rmse:0.69698\n[629]\tvalidation_0-rmse:0.69698\n[630]\tvalidation_0-rmse:0.69697\n[631]\tvalidation_0-rmse:0.69695\n[632]\tvalidation_0-rmse:0.69694\n[633]\tvalidation_0-rmse:0.69693\n[634]\tvalidation_0-rmse:0.69692\n[635]\tvalidation_0-rmse:0.69692\n[636]\tvalidation_0-rmse:0.69692\n[637]\tvalidation_0-rmse:0.69691\n[638]\tvalidation_0-rmse:0.69691\n[639]\tvalidation_0-rmse:0.69690\n[640]\tvalidation_0-rmse:0.69690\n[641]\tvalidation_0-rmse:0.69690\n[642]\tvalidation_0-rmse:0.69689\n[643]\tvalidation_0-rmse:0.69688\n[644]\tvalidation_0-rmse:0.69687\n[645]\tvalidation_0-rmse:0.69686\n[646]\tvalidation_0-rmse:0.69685\n[647]\tvalidation_0-rmse:0.69685\n[648]\tvalidation_0-rmse:0.69684\n[649]\tvalidation_0-rmse:0.69684\n[650]\tvalidation_0-rmse:0.69683\n[651]\tvalidation_0-rmse:0.69683\n[652]\tvalidation_0-rmse:0.69683\n[653]\tvalidation_0-rmse:0.69681\n[654]\tvalidation_0-rmse:0.69680\n[655]\tvalidation_0-rmse:0.69679\n[656]\tvalidation_0-rmse:0.69678\n[657]\tvalidation_0-rmse:0.69678\n[658]\tvalidation_0-rmse:0.69678\n[659]\tvalidation_0-rmse:0.69678\n[660]\tvalidation_0-rmse:0.69677\n[661]\tvalidation_0-rmse:0.69676\n[662]\tvalidation_0-rmse:0.69676\n[663]\tvalidation_0-rmse:0.69675\n[664]\tvalidation_0-rmse:0.69675\n[665]\tvalidation_0-rmse:0.69674\n[666]\tvalidation_0-rmse:0.69672\n[667]\tvalidation_0-rmse:0.69671\n[668]\tvalidation_0-rmse:0.69671\n[669]\tvalidation_0-rmse:0.69670\n[670]\tvalidation_0-rmse:0.69670\n[671]\tvalidation_0-rmse:0.69669\n[672]\tvalidation_0-rmse:0.69669\n[673]\tvalidation_0-rmse:0.69668\n[674]\tvalidation_0-rmse:0.69668\n[675]\tvalidation_0-rmse:0.69667\n[676]\tvalidation_0-rmse:0.69666\n[677]\tvalidation_0-rmse:0.69665\n[678]\tvalidation_0-rmse:0.69665\n[679]\tvalidation_0-rmse:0.69664\n[680]\tvalidation_0-rmse:0.69663\n[681]\tvalidation_0-rmse:0.69663\n[682]\tvalidation_0-rmse:0.69663\n[683]\tvalidation_0-rmse:0.69662\n[684]\tvalidation_0-rmse:0.69661\n[685]\tvalidation_0-rmse:0.69661\n[686]\tvalidation_0-rmse:0.69660\n[687]\tvalidation_0-rmse:0.69660\n[688]\tvalidation_0-rmse:0.69659\n[689]\tvalidation_0-rmse:0.69658\n[690]\tvalidation_0-rmse:0.69658\n[691]\tvalidation_0-rmse:0.69657\n[692]\tvalidation_0-rmse:0.69656\n[693]\tvalidation_0-rmse:0.69655\n[694]\tvalidation_0-rmse:0.69655\n[695]\tvalidation_0-rmse:0.69655\n[696]\tvalidation_0-rmse:0.69655\n[697]\tvalidation_0-rmse:0.69654\n[698]\tvalidation_0-rmse:0.69654\n[699]\tvalidation_0-rmse:0.69654\n[700]\tvalidation_0-rmse:0.69654\n[701]\tvalidation_0-rmse:0.69653\n[702]\tvalidation_0-rmse:0.69653\n[703]\tvalidation_0-rmse:0.69653\n[704]\tvalidation_0-rmse:0.69652\n[705]\tvalidation_0-rmse:0.69652\n[706]\tvalidation_0-rmse:0.69652\n[707]\tvalidation_0-rmse:0.69652\n[708]\tvalidation_0-rmse:0.69651\n[709]\tvalidation_0-rmse:0.69651\n[710]\tvalidation_0-rmse:0.69650\n[711]\tvalidation_0-rmse:0.69649\n[712]\tvalidation_0-rmse:0.69649\n[713]\tvalidation_0-rmse:0.69649\n[714]\tvalidation_0-rmse:0.69649\n[715]\tvalidation_0-rmse:0.69649\n[716]\tvalidation_0-rmse:0.69649\n[717]\tvalidation_0-rmse:0.69649\n[718]\tvalidation_0-rmse:0.69648\n[719]\tvalidation_0-rmse:0.69648\n[720]\tvalidation_0-rmse:0.69648\n[721]\tvalidation_0-rmse:0.69647\n[722]\tvalidation_0-rmse:0.69647\n[723]\tvalidation_0-rmse:0.69647\n[724]\tvalidation_0-rmse:0.69646\n[725]\tvalidation_0-rmse:0.69646\n[726]\tvalidation_0-rmse:0.69645\n[727]\tvalidation_0-rmse:0.69645\n[728]\tvalidation_0-rmse:0.69644\n[729]\tvalidation_0-rmse:0.69644\n[730]\tvalidation_0-rmse:0.69644\n[731]\tvalidation_0-rmse:0.69644\n[732]\tvalidation_0-rmse:0.69644\n[733]\tvalidation_0-rmse:0.69644\n[734]\tvalidation_0-rmse:0.69643\n[735]\tvalidation_0-rmse:0.69643\n[736]\tvalidation_0-rmse:0.69643\n[737]\tvalidation_0-rmse:0.69642\n[738]\tvalidation_0-rmse:0.69642\n[739]\tvalidation_0-rmse:0.69642\n[740]\tvalidation_0-rmse:0.69641\n[741]\tvalidation_0-rmse:0.69641\n[742]\tvalidation_0-rmse:0.69641\n[743]\tvalidation_0-rmse:0.69640\n[744]\tvalidation_0-rmse:0.69640\n[745]\tvalidation_0-rmse:0.69639\n[746]\tvalidation_0-rmse:0.69639\n[747]\tvalidation_0-rmse:0.69639\n[748]\tvalidation_0-rmse:0.69639\n[749]\tvalidation_0-rmse:0.69639\n[750]\tvalidation_0-rmse:0.69638\n[751]\tvalidation_0-rmse:0.69637\n[752]\tvalidation_0-rmse:0.69638\n[753]\tvalidation_0-rmse:0.69637\n[754]\tvalidation_0-rmse:0.69636\n[755]\tvalidation_0-rmse:0.69636\n[756]\tvalidation_0-rmse:0.69635\n[757]\tvalidation_0-rmse:0.69635\n[758]\tvalidation_0-rmse:0.69635\n[759]\tvalidation_0-rmse:0.69634\n[760]\tvalidation_0-rmse:0.69634\n[761]\tvalidation_0-rmse:0.69634\n[762]\tvalidation_0-rmse:0.69633\n","name":"stdout"},{"output_type":"stream","text":"[763]\tvalidation_0-rmse:0.69632\n[764]\tvalidation_0-rmse:0.69632\n[765]\tvalidation_0-rmse:0.69632\n[766]\tvalidation_0-rmse:0.69632\n[767]\tvalidation_0-rmse:0.69632\n[768]\tvalidation_0-rmse:0.69632\n[769]\tvalidation_0-rmse:0.69631\n[770]\tvalidation_0-rmse:0.69631\n[771]\tvalidation_0-rmse:0.69630\n[772]\tvalidation_0-rmse:0.69630\n[773]\tvalidation_0-rmse:0.69630\n[774]\tvalidation_0-rmse:0.69630\n[775]\tvalidation_0-rmse:0.69630\n[776]\tvalidation_0-rmse:0.69629\n[777]\tvalidation_0-rmse:0.69629\n[778]\tvalidation_0-rmse:0.69629\n[779]\tvalidation_0-rmse:0.69628\n[780]\tvalidation_0-rmse:0.69628\n[781]\tvalidation_0-rmse:0.69627\n[782]\tvalidation_0-rmse:0.69627\n[783]\tvalidation_0-rmse:0.69627\n[784]\tvalidation_0-rmse:0.69627\n[785]\tvalidation_0-rmse:0.69627\n[786]\tvalidation_0-rmse:0.69626\n[787]\tvalidation_0-rmse:0.69626\n[788]\tvalidation_0-rmse:0.69626\n[789]\tvalidation_0-rmse:0.69625\n[790]\tvalidation_0-rmse:0.69625\n[791]\tvalidation_0-rmse:0.69625\n[792]\tvalidation_0-rmse:0.69624\n[793]\tvalidation_0-rmse:0.69624\n[794]\tvalidation_0-rmse:0.69624\n[795]\tvalidation_0-rmse:0.69623\n[796]\tvalidation_0-rmse:0.69623\n[797]\tvalidation_0-rmse:0.69623\n[798]\tvalidation_0-rmse:0.69622\n[799]\tvalidation_0-rmse:0.69622\n[800]\tvalidation_0-rmse:0.69622\n[801]\tvalidation_0-rmse:0.69622\n[802]\tvalidation_0-rmse:0.69621\n[803]\tvalidation_0-rmse:0.69620\n[804]\tvalidation_0-rmse:0.69620\n[805]\tvalidation_0-rmse:0.69620\n[806]\tvalidation_0-rmse:0.69620\n[807]\tvalidation_0-rmse:0.69620\n[808]\tvalidation_0-rmse:0.69620\n[809]\tvalidation_0-rmse:0.69620\n[810]\tvalidation_0-rmse:0.69620\n[811]\tvalidation_0-rmse:0.69619\n[812]\tvalidation_0-rmse:0.69619\n[813]\tvalidation_0-rmse:0.69619\n[814]\tvalidation_0-rmse:0.69619\n[815]\tvalidation_0-rmse:0.69619\n[816]\tvalidation_0-rmse:0.69618\n[817]\tvalidation_0-rmse:0.69618\n[818]\tvalidation_0-rmse:0.69618\n[819]\tvalidation_0-rmse:0.69618\n[820]\tvalidation_0-rmse:0.69618\n[821]\tvalidation_0-rmse:0.69618\n[822]\tvalidation_0-rmse:0.69618\n[823]\tvalidation_0-rmse:0.69617\n[824]\tvalidation_0-rmse:0.69617\n[825]\tvalidation_0-rmse:0.69617\n[826]\tvalidation_0-rmse:0.69616\n[827]\tvalidation_0-rmse:0.69616\n[828]\tvalidation_0-rmse:0.69615\n[829]\tvalidation_0-rmse:0.69615\n[830]\tvalidation_0-rmse:0.69615\n[831]\tvalidation_0-rmse:0.69615\n[832]\tvalidation_0-rmse:0.69615\n[833]\tvalidation_0-rmse:0.69615\n[834]\tvalidation_0-rmse:0.69615\n[835]\tvalidation_0-rmse:0.69614\n[836]\tvalidation_0-rmse:0.69614\n[837]\tvalidation_0-rmse:0.69613\n[838]\tvalidation_0-rmse:0.69613\n[839]\tvalidation_0-rmse:0.69612\n[840]\tvalidation_0-rmse:0.69612\n[841]\tvalidation_0-rmse:0.69612\n[842]\tvalidation_0-rmse:0.69612\n[843]\tvalidation_0-rmse:0.69612\n[844]\tvalidation_0-rmse:0.69612\n[845]\tvalidation_0-rmse:0.69611\n[846]\tvalidation_0-rmse:0.69612\n[847]\tvalidation_0-rmse:0.69612\n[848]\tvalidation_0-rmse:0.69612\n[849]\tvalidation_0-rmse:0.69612\n[850]\tvalidation_0-rmse:0.69612\n[851]\tvalidation_0-rmse:0.69611\n[852]\tvalidation_0-rmse:0.69610\n[853]\tvalidation_0-rmse:0.69610\n[854]\tvalidation_0-rmse:0.69610\n[855]\tvalidation_0-rmse:0.69610\n[856]\tvalidation_0-rmse:0.69610\n[857]\tvalidation_0-rmse:0.69610\n[858]\tvalidation_0-rmse:0.69610\n[859]\tvalidation_0-rmse:0.69609\n[860]\tvalidation_0-rmse:0.69610\n[861]\tvalidation_0-rmse:0.69608\n[862]\tvalidation_0-rmse:0.69608\n[863]\tvalidation_0-rmse:0.69608\n[864]\tvalidation_0-rmse:0.69608\n[865]\tvalidation_0-rmse:0.69608\n[866]\tvalidation_0-rmse:0.69608\n[867]\tvalidation_0-rmse:0.69609\n[868]\tvalidation_0-rmse:0.69608\n[869]\tvalidation_0-rmse:0.69608\n[870]\tvalidation_0-rmse:0.69608\n[871]\tvalidation_0-rmse:0.69608\n[872]\tvalidation_0-rmse:0.69608\n[873]\tvalidation_0-rmse:0.69608\n[874]\tvalidation_0-rmse:0.69608\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"XGBRegressor(alpha=0.01563, base_score=0.5, booster='gbtree',\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.5,\n             gamma=0, gpu_id=-1, importance_type='gain',\n             interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n             max_depth=15, metric_period=100, min_child_weight=257, missing=nan,\n             monotone_constraints='()', n_estimators=4000, n_jobs=4,\n             num_parallel_tree=1, random_state=2020, reg_alpha=0.0156299993,\n             reg_lambda=0.003, scale_pos_weight=1, silent=1, subsample=0.7,\n             tree_method='exact', validate_parameters=1, verbosity=None)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#===========================================================================\n# use the model XGB to predict the prices for the test data\n#===========================================================================\npredictions = regressor.predict(final_X_test)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data.drop(['id','target'], axis=1)\nXtest = test_data.drop(['id'], axis=1)\ny = train_data['target']\n\ntrain = int(len(X)*0.85)\nXtrain, Xval = X.iloc[:train], X.iloc[train:]\nytrain, yval = y.iloc[:train], y.iloc[train:]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params from this kernel https://www.kaggle.com/kailex/tabular-playground\n\nparams={'random_state': 33,'n_estimators':5000,\n 'min_data_per_group': 5,\n 'boosting_type': 'gbdt',\n 'num_leaves': 256,\n 'max_dept': -1,\n 'learning_rate': 0.02,\n 'subsample_for_bin': 200000,\n 'lambda_l1': 1.074622455507616e-05,\n 'lambda_l2': 2.0521330798729704e-06,\n 'n_jobs': -1,\n 'cat_smooth': 1.0,\n 'silent': True,\n 'importance_type': 'split',\n 'metric': 'rmse',\n 'feature_pre_filter': False,\n 'bagging_fraction': 0.8206341150202605,\n 'min_data_in_leaf': 100,\n 'min_sum_hessian_in_leaf': 0.001,\n 'bagging_freq': 6,\n 'feature_fraction': 0.5,\n 'min_gain_to_split': 0.0,\n 'min_child_samples': 20}","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\nfrom sklearn.model_selection import KFold\n\nN_FOLDS = 7\n\nkf = KFold(n_splits = N_FOLDS)\noof = np.zeros(len(y))\noof_vanilla = np.zeros(len(y))\npreds = np.zeros(len(Xtest))\nparams['learning_rate'] = 0.005\nparams['num_iterations'] = 5000\nfor train_ind, test_ind in tqdm(kf.split(X)):\n    Xtrain = X.iloc[train_ind]\n    Xval = X.iloc[test_ind]\n    ytrain = y.iloc[train_ind]\n    yval = y.iloc[test_ind]\n\n    model = LGBMRegressor(**params)\n    vanilla_model = LGBMRegressor()\n    \n    model.fit(Xtrain, ytrain, eval_set = ((Xval,yval)), early_stopping_rounds = 50, verbose = 0)\n    vanilla_model.fit(Xtrain, ytrain)\n    p = model.predict(Xval)\n    p_vanilla = vanilla_model.predict(Xval)\n    oof[test_ind] = p\n    oof_vanilla[test_ind] = p_vanilla\n    \n    preds += model.predict(Xtest)/N_FOLDS\n    \nprint(f'mean square error on training data (vanilla model): {np.round(mean_squared_error(y, oof_vanilla, squared=False),5)}')    \nprint(f'mean square error on training data (with optuna tuning): {np.round(mean_squared_error(y, oof, squared=False),5)}')","execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}},{"output_type":"stream","text":"0it [00:00, ?it/s]/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"\r1it [03:23, 203.22s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"\r2it [07:00, 211.47s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"\r3it [10:43, 216.65s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"\r4it [14:56, 231.10s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"\r5it [18:23, 222.47s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"\r6it [22:31, 231.17s/it]","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"7it [25:23, 217.59s/it]","name":"stderr"},{"output_type":"stream","text":"mean square error on training data (vanilla model): 0.70252\nmean square error on training data (with optuna tuning): 0.69566\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_data.drop(['id','target'], axis=1)\nXtest = test_data.drop(['id'], axis=1)\ny = train_data['target']","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntmp=X.copy()\nimport random\nfold_list = [1,2,3,4,5,6,7]\nfolds = []\nfor i in range(int((tmp.shape[0])/7)):\n    random.shuffle(fold_list)\n    folds.extend(fold_list)\nfolds=folds+[1]\ntmp['fold'] = folds\ntmp.head(7)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"      cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n0  0.670390  0.811300  0.643968  0.291791  0.284117  0.855953  0.890700   \n1  0.388053  0.621104  0.686102  0.501149  0.643790  0.449805  0.510824   \n2  0.834950  0.227436  0.301584  0.293408  0.606839  0.829175  0.506143   \n3  0.820708  0.160155  0.546887  0.726104  0.282444  0.785108  0.752758   \n4  0.935278  0.421235  0.303801  0.880214  0.665610  0.830131  0.487113   \n5  0.352623  0.258867  0.327373  0.802627  0.284219  0.296886  0.209743   \n6  0.259096  0.803934  0.580900  0.322884  0.984705  0.378247  0.432821   \n\n      cont8     cont9    cont10    cont11    cont12    cont13    cont14  fold  \n0  0.285542  0.558245  0.779418  0.921832  0.866772  0.878733  0.305411     2  \n1  0.580748  0.418335  0.432632  0.439872  0.434971  0.369957  0.369484     1  \n2  0.558771  0.587603  0.823312  0.567007  0.677708  0.882938  0.303047     4  \n3  0.823267  0.574466  0.580843  0.769594  0.818143  0.914281  0.279528     7  \n4  0.604157  0.874658  0.863427  0.983575  0.900464  0.935918  0.435772     3  \n5  0.273710  0.308018  0.235851  0.278760  0.251406  0.339135  0.293129     6  \n6  0.562059  0.290965  0.316543  0.219192  0.326977  0.458653  0.244300     5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>cont14</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.670390</td>\n      <td>0.811300</td>\n      <td>0.643968</td>\n      <td>0.291791</td>\n      <td>0.284117</td>\n      <td>0.855953</td>\n      <td>0.890700</td>\n      <td>0.285542</td>\n      <td>0.558245</td>\n      <td>0.779418</td>\n      <td>0.921832</td>\n      <td>0.866772</td>\n      <td>0.878733</td>\n      <td>0.305411</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.388053</td>\n      <td>0.621104</td>\n      <td>0.686102</td>\n      <td>0.501149</td>\n      <td>0.643790</td>\n      <td>0.449805</td>\n      <td>0.510824</td>\n      <td>0.580748</td>\n      <td>0.418335</td>\n      <td>0.432632</td>\n      <td>0.439872</td>\n      <td>0.434971</td>\n      <td>0.369957</td>\n      <td>0.369484</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.834950</td>\n      <td>0.227436</td>\n      <td>0.301584</td>\n      <td>0.293408</td>\n      <td>0.606839</td>\n      <td>0.829175</td>\n      <td>0.506143</td>\n      <td>0.558771</td>\n      <td>0.587603</td>\n      <td>0.823312</td>\n      <td>0.567007</td>\n      <td>0.677708</td>\n      <td>0.882938</td>\n      <td>0.303047</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.820708</td>\n      <td>0.160155</td>\n      <td>0.546887</td>\n      <td>0.726104</td>\n      <td>0.282444</td>\n      <td>0.785108</td>\n      <td>0.752758</td>\n      <td>0.823267</td>\n      <td>0.574466</td>\n      <td>0.580843</td>\n      <td>0.769594</td>\n      <td>0.818143</td>\n      <td>0.914281</td>\n      <td>0.279528</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.935278</td>\n      <td>0.421235</td>\n      <td>0.303801</td>\n      <td>0.880214</td>\n      <td>0.665610</td>\n      <td>0.830131</td>\n      <td>0.487113</td>\n      <td>0.604157</td>\n      <td>0.874658</td>\n      <td>0.863427</td>\n      <td>0.983575</td>\n      <td>0.900464</td>\n      <td>0.935918</td>\n      <td>0.435772</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.352623</td>\n      <td>0.258867</td>\n      <td>0.327373</td>\n      <td>0.802627</td>\n      <td>0.284219</td>\n      <td>0.296886</td>\n      <td>0.209743</td>\n      <td>0.273710</td>\n      <td>0.308018</td>\n      <td>0.235851</td>\n      <td>0.278760</td>\n      <td>0.251406</td>\n      <td>0.339135</td>\n      <td>0.293129</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.259096</td>\n      <td>0.803934</td>\n      <td>0.580900</td>\n      <td>0.322884</td>\n      <td>0.984705</td>\n      <td>0.378247</td>\n      <td>0.432821</td>\n      <td>0.562059</td>\n      <td>0.290965</td>\n      <td>0.316543</td>\n      <td>0.219192</td>\n      <td>0.326977</td>\n      <td>0.458653</td>\n      <td>0.244300</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.zeros(len(Xtest))\nfor fold in range(1,8):\n    train_index_list = tmp[tmp['fold'] != fold].index\n    test_index_list = tmp[tmp['fold'] == fold].index\n                          \n    X_train = X.iloc[train_index_list]\n    y_train = y.iloc[train_index_list]\n    X_val = X.iloc[test_index_list]\n    y_val = y.iloc[test_index_list]\n\n    model=LGBMRegressor(**params)\n    eval_set = [(X_val, y_val)]\n    model.fit(X_train, y_train,eval_metric='rmse', eval_set=eval_set, verbose=False)#,early_stopping_rounds=5,\n    predictions += model.predict(Xtest)\npredictions = predictions/7","execution_count":12,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n","name":"stderr"},{"output_type":"stream","text":"[LightGBM] [Warning] Unknown parameter: max_dept\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] lambda_l1 is set=1.074622455507616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.074622455507616e-05\n[LightGBM] [Warning] bagging_fraction is set=0.8206341150202605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8206341150202605\n[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001\n[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n[LightGBM] [Warning] min_gain_to_split is set=0.0, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.0\n[LightGBM] [Warning] lambda_l2 is set=2.0521330798729704e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0521330798729704e-06\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtest[\"target\"]=predictions","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtest.head()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"      cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n0  0.353600  0.738780  0.600939  0.293377  0.285691  0.458006  0.620704   \n1  0.907222  0.189756  0.215531  0.869915  0.301333  0.528958  0.390351   \n2  0.179287  0.355353  0.623972  0.437812  0.282476  0.320826  0.386789   \n3  0.359385  0.181049  0.551368  0.206386  0.280763  0.482076  0.506677   \n4  0.335791  0.682607  0.676481  0.219465  0.282861  0.581721  0.748639   \n\n      cont8     cont9    cont10    cont11    cont12    cont13    cont14  \\\n0  0.422249  0.369203  0.435727  0.550540  0.699134  0.286864  0.364515   \n1  0.521112  0.794779  0.798580  0.446475  0.449037  0.916964  0.513002   \n2  0.776422  0.222268  0.229102  0.211913  0.222651  0.327164  0.827941   \n3  0.362793  0.379737  0.345686  0.445276  0.518485  0.299028  0.598166   \n4  0.350158  0.448915  0.506878  0.817721  0.805895  0.790591  0.249275   \n\n     target  \n0  7.918180  \n1  7.903751  \n2  7.925541  \n3  8.277034  \n4  8.083853  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cont1</th>\n      <th>cont2</th>\n      <th>cont3</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>cont14</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.353600</td>\n      <td>0.738780</td>\n      <td>0.600939</td>\n      <td>0.293377</td>\n      <td>0.285691</td>\n      <td>0.458006</td>\n      <td>0.620704</td>\n      <td>0.422249</td>\n      <td>0.369203</td>\n      <td>0.435727</td>\n      <td>0.550540</td>\n      <td>0.699134</td>\n      <td>0.286864</td>\n      <td>0.364515</td>\n      <td>7.918180</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.907222</td>\n      <td>0.189756</td>\n      <td>0.215531</td>\n      <td>0.869915</td>\n      <td>0.301333</td>\n      <td>0.528958</td>\n      <td>0.390351</td>\n      <td>0.521112</td>\n      <td>0.794779</td>\n      <td>0.798580</td>\n      <td>0.446475</td>\n      <td>0.449037</td>\n      <td>0.916964</td>\n      <td>0.513002</td>\n      <td>7.903751</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.179287</td>\n      <td>0.355353</td>\n      <td>0.623972</td>\n      <td>0.437812</td>\n      <td>0.282476</td>\n      <td>0.320826</td>\n      <td>0.386789</td>\n      <td>0.776422</td>\n      <td>0.222268</td>\n      <td>0.229102</td>\n      <td>0.211913</td>\n      <td>0.222651</td>\n      <td>0.327164</td>\n      <td>0.827941</td>\n      <td>7.925541</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.359385</td>\n      <td>0.181049</td>\n      <td>0.551368</td>\n      <td>0.206386</td>\n      <td>0.280763</td>\n      <td>0.482076</td>\n      <td>0.506677</td>\n      <td>0.362793</td>\n      <td>0.379737</td>\n      <td>0.345686</td>\n      <td>0.445276</td>\n      <td>0.518485</td>\n      <td>0.299028</td>\n      <td>0.598166</td>\n      <td>8.277034</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.335791</td>\n      <td>0.682607</td>\n      <td>0.676481</td>\n      <td>0.219465</td>\n      <td>0.282861</td>\n      <td>0.581721</td>\n      <td>0.748639</td>\n      <td>0.350158</td>\n      <td>0.448915</td>\n      <td>0.506878</td>\n      <td>0.817721</td>\n      <td>0.805895</td>\n      <td>0.790591</td>\n      <td>0.249275</td>\n      <td>8.083853</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"output=pd.DataFrame({\"id\":test_data.id, \"target\":predictions})\noutput.to_csv('submission7.csv', index=False)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"            id    target\n0            0  7.918180\n1            2  7.903751\n2            6  7.925541\n3            7  8.277034\n4           10  8.083853\n...        ...       ...\n199995  499984  8.189553\n199996  499985  8.166483\n199997  499987  8.214797\n199998  499988  8.039639\n199999  499990  7.945607\n\n[200000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7.918180</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>7.903751</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>7.925541</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>8.277034</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>8.083853</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>499984</td>\n      <td>8.189553</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>499985</td>\n      <td>8.166483</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>499987</td>\n      <td>8.214797</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>499988</td>\n      <td>8.039639</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>499990</td>\n      <td>7.945607</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 2 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}