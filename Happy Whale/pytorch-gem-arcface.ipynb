{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#https://www.kaggle.com/code/debarshichanda/pytorch-arcface-gem-pooling-starter/notebook","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:07.760674Z","iopub.execute_input":"2022-04-09T12:57:07.760940Z","iopub.status.idle":"2022-04-09T12:57:07.764733Z","shell.execute_reply.started":"2022-04-09T12:57:07.760911Z","shell.execute_reply":"2022-04-09T12:57:07.763970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-09T12:57:07.766401Z","iopub.execute_input":"2022-04-09T12:57:07.768123Z","iopub.status.idle":"2022-04-09T12:57:07.775078Z","shell.execute_reply.started":"2022-04-09T12:57:07.768082Z","shell.execute_reply":"2022-04-09T12:57:07.774226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install timm","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:07.784163Z","iopub.execute_input":"2022-04-09T12:57:07.785742Z","iopub.status.idle":"2022-04-09T12:57:15.907390Z","shell.execute_reply.started":"2022-04-09T12:57:07.785715Z","shell.execute_reply":"2022-04-09T12:57:15.906533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport cv2\nimport math\nimport time\nimport random\n\n#Pytorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\n\n#Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n#Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n#Convert image and mask to torch.Tensor. The numpy HWC image is converted to pytorch CHW tensor\n\n#For descriptive error messages\nos.environ[\"CUDA_LAUNCH_BLOSKING\"]= \"1\"","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:15.909590Z","iopub.execute_input":"2022-04-09T12:57:15.909857Z","iopub.status.idle":"2022-04-09T12:57:15.916766Z","shell.execute_reply.started":"2022-04-09T12:57:15.909823Z","shell.execute_reply":"2022-04-09T12:57:15.916098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"wand_api\")\n    wandb.login(key=api_key)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:15.918205Z","iopub.execute_input":"2022-04-09T12:57:15.918720Z","iopub.status.idle":"2022-04-09T12:57:16.485889Z","shell.execute_reply.started":"2022-04-09T12:57:15.918685Z","shell.execute_reply":"2022-04-09T12:57:16.485023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=123):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.489718Z","iopub.execute_input":"2022-04-09T12:57:16.489939Z","iopub.status.idle":"2022-04-09T12:57:16.497331Z","shell.execute_reply.started":"2022-04-09T12:57:16.489913Z","shell.execute_reply":"2022-04-09T12:57:16.496617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training configuration","metadata":{}},{"cell_type":"code","source":"CONFIG = {\"seed\": 2022,\n         \"epochs\":4,\n         \"img_size\":448,\n         \"model_name\": \"efficientnet_b0\",\n         \"num_classes\": 15587,\n         \"embedding_size\":512,\n         \"train_batch_size\":32,\n         \"valid_batch_size\": 64,\n          \"learning_rate\":1e-4,\n          \"scheduler\": \"CosineAnnealingLR\",\n          \"min_lr\": 1e-6,\n          \"T_max\":500,\n          \"weight_decay\":1e-6,\n          \"n_fold\":5,\n          \"n_accumulate\":1,\n          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n          \n          #ArcFace Hyperparameters\n          #https://qiita.com/yu4u/items/078054dfb5592cbb80cc\n          \"s\":28.0, #30.0\n          \"m\":0.50,\n          \"ls_eps\": 0.0,\n          \"easy_margin\":False\n         }","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.499920Z","iopub.execute_input":"2022-04-09T12:57:16.500492Z","iopub.status.idle":"2022-04-09T12:57:16.553758Z","shell.execute_reply.started":"2022-04-09T12:57:16.500459Z","shell.execute_reply":"2022-04-09T12:57:16.552941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_seed(CONFIG[\"seed\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.556809Z","iopub.execute_input":"2022-04-09T12:57:16.557230Z","iopub.status.idle":"2022-04-09T12:57:16.566882Z","shell.execute_reply.started":"2022-04-09T12:57:16.557196Z","shell.execute_reply":"2022-04-09T12:57:16.566187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '../input/happy-whale-and-dolphin'\nTRAIN_DIR = '../input/happy-whale-and-dolphin/train_images'\nTEST_DIR = '../input/happy-whale-and-dolphin/test_images'","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.568355Z","iopub.execute_input":"2022-04-09T12:57:16.568706Z","iopub.status.idle":"2022-04-09T12:57:16.574569Z","shell.execute_reply.started":"2022-04-09T12:57:16.568666Z","shell.execute_reply":"2022-04-09T12:57:16.573605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(id):\n    return f\"{TRAIN_DIR}/{id}\"","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.576339Z","iopub.execute_input":"2022-04-09T12:57:16.577217Z","iopub.status.idle":"2022-04-09T12:57:16.583865Z","shell.execute_reply.started":"2022-04-09T12:57:16.577148Z","shell.execute_reply":"2022-04-09T12:57:16.582642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/happy-whale-and-dolphin/train.csv\")\ntrain_df.species.replace({\"globis\": \"short_finned_pilot_whale\",\n                          \"pilot_whale\": \"short_finned_pilot_whale\",\n                          \"kiler_whale\": \"killer_whale\",\n                          \"bottlenose_dolpin\": \"bottlenose_dolphin\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.585527Z","iopub.execute_input":"2022-04-09T12:57:16.586027Z","iopub.status.idle":"2022-04-09T12:57:16.697601Z","shell.execute_reply.started":"2022-04-09T12:57:16.585989Z","shell.execute_reply":"2022-04-09T12:57:16.696773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read the Data","metadata":{}},{"cell_type":"code","source":"train_df[\"file_path\"] = train_df[\"image\"].apply(get_train_file_path)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.701180Z","iopub.execute_input":"2022-04-09T12:57:16.701414Z","iopub.status.idle":"2022-04-09T12:57:16.728882Z","shell.execute_reply.started":"2022-04-09T12:57:16.701381Z","shell.execute_reply":"2022-04-09T12:57:16.727914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ntrain_df[\"individual_id\"]= encoder.fit_transform(train_df[\"individual_id\"])\n\nwith open(\"le.pkl\", \"wb\") as fp:\n    joblib.dump(encoder, fp)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.732600Z","iopub.execute_input":"2022-04-09T12:57:16.733103Z","iopub.status.idle":"2022-04-09T12:57:16.790898Z","shell.execute_reply.started":"2022-04-09T12:57:16.733069Z","shell.execute_reply":"2022-04-09T12:57:16.790227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.792077Z","iopub.execute_input":"2022-04-09T12:57:16.792629Z","iopub.status.idle":"2022-04-09T12:57:16.810833Z","shell.execute_reply.started":"2022-04-09T12:57:16.792600Z","shell.execute_reply":"2022-04-09T12:57:16.810145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Folds","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=CONFIG[\"n_fold\"])\n\nfor fold, (_,val_) in enumerate(skf.split(X=train_df, y=train_df.individual_id)):\n    train_df.loc[val_, \"kfold\"] = fold","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:16.812179Z","iopub.execute_input":"2022-04-09T12:57:16.812898Z","iopub.status.idle":"2022-04-09T12:57:17.280219Z","shell.execute_reply.started":"2022-04-09T12:57:16.812860Z","shell.execute_reply":"2022-04-09T12:57:17.279470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Class","metadata":{}},{"cell_type":"code","source":"class HappyWhaleDataset(Dataset):\n    def __init__(self, df,transforms=None):\n        self.df = df\n        self.file_names = df[\"file_path\"].values\n        self.labels=df[\"individual_id\"].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,index):\n        img_path= self.file_names[index]\n        img = cv2.imread(img_path)\n        img =cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        label = self.labels[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]#albumentation\n            \n        return {\n            \"image\" : img,\n            \"label\" : torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:17.281799Z","iopub.execute_input":"2022-04-09T12:57:17.282226Z","iopub.status.idle":"2022-04-09T12:57:17.290625Z","shell.execute_reply.started":"2022-04-09T12:57:17.282187Z","shell.execute_reply":"2022-04-09T12:57:17.289846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.ShiftScaleRotate(shift_limit=0.1, \n                           scale_limit=0.15, \n                           rotate_limit=60, \n                           p=0.5),\n        A.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n        A.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.),\n    \n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:17.291826Z","iopub.execute_input":"2022-04-09T12:57:17.292147Z","iopub.status.idle":"2022-04-09T12:57:17.303331Z","shell.execute_reply.started":"2022-04-09T12:57:17.292109Z","shell.execute_reply":"2022-04-09T12:57:17.302596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://amaarora.github.io/2020/08/30/gempool.html\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = nn.Parameter(torch.ones(1)*9)\n        self.eps = eps\n        \n    def forward(self,x):\n        return self.gem(x, p=self.p, eps=self.eps)\n    \n    def gem(self, x, p=3, eps=1e-6):\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n        \n    def __repr__(self):\n        return self.__class__.__name__ + \\\n                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n                ', ' + 'eps=' + str(self.eps) + ')'","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:17.304485Z","iopub.execute_input":"2022-04-09T12:57:17.305236Z","iopub.status.idle":"2022-04-09T12:57:17.316212Z","shell.execute_reply.started":"2022-04-09T12:57:17.305199Z","shell.execute_reply":"2022-04-09T12:57:17.315469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ArcFace","metadata":{}},{"cell_type":"code","source":"class ArcMarginProduct(nn.Module):\n    \"\"\"Implement of large margin arc distance::\n        Args:\n          in_features: size of each input sample\n          out_features: size of each output sample\n          s: norn of input feature\n          m: margin\n          cos(theta+m)\n          \"\"\"\n    \n    def __init__(self, in_features, out_features,s=30.0,m=0.5, easy_margin=False, ls_eps=0.0):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s=s\n        self.m=m\n        self.ls_eps = ls_eps #label smoothing\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform(self.weight)\n        \n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n        \n    def forward(self, input,label):\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        sine = torch.sqrt(1.0 - torch.pow(cosine,2))\n        phi = cosine * self.cos_m - sine*self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi=torch.where(cosine > self.th, phi, cosine-self.mm)\n        \n        one_hot = torch.zeros(cosine.size(), device=CONFIG['device'])\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        \n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:17.317674Z","iopub.execute_input":"2022-04-09T12:57:17.317964Z","iopub.status.idle":"2022-04-09T12:57:17.332551Z","shell.execute_reply.started":"2022-04-09T12:57:17.317928Z","shell.execute_reply":"2022-04-09T12:57:17.331807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"class HappyWhaleModel(nn.Module):\n    def __init__(self, model_name, embedding_size, pretrained=True):\n        super(HappyWhaleModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features=self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.model.global_pool = nn.Identity()\n        self.pooling = GeM()\n        self.embedding = nn.Linear(in_features, embedding_size)\n        \n        self.fc=ArcMarginProduct(embedding_size, \n                                 CONFIG[\"num_classes\"],\n                                s=CONFIG[\"s\"],\n                                m=CONFIG[\"m\"],\n                                easy_margin=CONFIG[\"easy_margin\"],\n                                ls_eps=CONFIG[\"ls_eps\"])\n    \n    def forward(self, images, labels):\n        features = self.model(images)\n        pooled_features = self.pooling(features).flatten(1)\n        embedding = self.embedding(pooled_features)\n        output= self.fc(embedding, labels)\n        return output\n    \n    def extract(self, images):\n        features=self.model(images)\n        pooled_features = self.pooling(features).flatten(1)\n        embedding = self.embedding(pooled_features)\n        return embedding\n    \n\nmodel = HappyWhaleModel(CONFIG[\"model_name\"], CONFIG[\"embedding_size\"])\nmodel.to(CONFIG[\"device\"]);","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:17.334067Z","iopub.execute_input":"2022-04-09T12:57:17.334612Z","iopub.status.idle":"2022-04-09T12:57:22.270381Z","shell.execute_reply.started":"2022-04-09T12:57:17.334573Z","shell.execute_reply":"2022-04-09T12:57:22.269502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Loss Function**","metadata":{}},{"cell_type":"code","source":"def criterion(outputs, labels):\n    return nn.CrossEntropyLoss()(outputs, labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.271883Z","iopub.execute_input":"2022-04-09T12:57:22.272162Z","iopub.status.idle":"2022-04-09T12:57:22.276312Z","shell.execute_reply.started":"2022-04-09T12:57:22.272123Z","shell.execute_reply":"2022-04-09T12:57:22.275651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Function","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    \n    dataset_size=0\n    running_loss = 0.0\n    \n    bar=tqdm(enumerate(dataloader), total=len(dataloader))\n    for step,data in bar:\n        images = data['image'].to(device, dtype=torch.float)\n        labels = data['label'].to(device, dtype=torch.long)\n        \n        batch_size = images.size(0)\n        \n        outputs = model(images, labels)\n        loss = criterion(outputs, labels)\n        loss = loss / CONFIG['n_accumulate']\n            \n        loss.backward()\n        \n        \n        if (step + 1) % CONFIG['n_accumulate'] == 0:\n            optimizer.step()\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            if scheduler is not None:\n                scheduler.step()\n                \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.277786Z","iopub.execute_input":"2022-04-09T12:57:22.278318Z","iopub.status.idle":"2022-04-09T12:57:22.289707Z","shell.execute_reply.started":"2022-04-09T12:57:22.278277Z","shell.execute_reply":"2022-04-09T12:57:22.288898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# validation function","metadata":{}},{"cell_type":"code","source":"@torch.inference_mode()\ndef valid_one_epoch(model, dataloader, device, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:        \n        images = data['image'].to(device, dtype=torch.float)\n        labels = data['label'].to(device, dtype=torch.long)\n        \n        batch_size = images.size(0)\n\n        outputs = model(images, labels)\n        loss = criterion(outputs, labels)\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss / dataset_size\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])   \n    \n    gc.collect()\n    \n    return epoch_loss","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.291250Z","iopub.execute_input":"2022-04-09T12:57:22.291543Z","iopub.status.idle":"2022-04-09T12:57:22.303434Z","shell.execute_reply.started":"2022-04-09T12:57:22.291500Z","shell.execute_reply":"2022-04-09T12:57:22.302724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run training","metadata":{}},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    # To automatically log gradients\n    wandb.watch(model, log_freq=100)\n    \n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_loss = np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, scheduler, \n                                           dataloader=train_loader, \n                                           device=CONFIG['device'], epoch=epoch)\n        \n        val_epoch_loss = valid_one_epoch(model, valid_loader, device=CONFIG['device'], \n                                         epoch=epoch)\n    \n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(val_epoch_loss)\n        \n        # Log the metrics\n        wandb.log({\"Train Loss\": train_epoch_loss})\n        wandb.log({\"Valid Loss\": val_epoch_loss})\n        \n        # deep copy the model\n        if val_epoch_loss <= best_epoch_loss:\n            print(f\"{b_}Validation Loss Improved ({best_epoch_loss} ---> {val_epoch_loss})\")\n            best_epoch_loss = val_epoch_loss\n            run.summary[\"Best Loss\"] = best_epoch_loss\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_loss, epoch)\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best Loss: {:.4f}\".format(best_epoch_loss))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.305139Z","iopub.execute_input":"2022-04-09T12:57:22.305473Z","iopub.status.idle":"2022-04-09T12:57:22.320674Z","shell.execute_reply.started":"2022-04-09T12:57:22.305433Z","shell.execute_reply":"2022-04-09T12:57:22.319816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n                                                             eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.323103Z","iopub.execute_input":"2022-04-09T12:57:22.323662Z","iopub.status.idle":"2022-04-09T12:57:22.331530Z","shell.execute_reply.started":"2022-04-09T12:57:22.323624Z","shell.execute_reply":"2022-04-09T12:57:22.330572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df, fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n    \n    train_dataset = HappyWhaleDataset(df_train, transforms=data_transforms[\"train\"])\n    valid_dataset = HappyWhaleDataset(df_valid, transforms=data_transforms[\"valid\"])\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=2, shuffle=False, pin_memory=True)\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.333107Z","iopub.execute_input":"2022-04-09T12:57:22.333439Z","iopub.status.idle":"2022-04-09T12:57:22.343191Z","shell.execute_reply.started":"2022-04-09T12:57:22.333400Z","shell.execute_reply":"2022-04-09T12:57:22.342465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader, valid_loader = prepare_loaders(train_df, fold=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.345911Z","iopub.execute_input":"2022-04-09T12:57:22.346772Z","iopub.status.idle":"2022-04-09T12:57:22.366094Z","shell.execute_reply.started":"2022-04-09T12:57:22.346729Z","shell.execute_reply":"2022-04-09T12:57:22.365378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n                       weight_decay=CONFIG['weight_decay'])\nscheduler = fetch_scheduler(optimizer)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.367714Z","iopub.execute_input":"2022-04-09T12:57:22.368115Z","iopub.status.idle":"2022-04-09T12:57:22.374507Z","shell.execute_reply.started":"2022-04-09T12:57:22.368078Z","shell.execute_reply":"2022-04-09T12:57:22.373772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run = wandb.init(project='HappyWhale', \n                 config=CONFIG,\n                 job_type='Train',\n                 tags=['arcface', 'gem-pooling', 'effnet-b0-ns', '448'],\n                 anonymous='must')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:22.377084Z","iopub.execute_input":"2022-04-09T12:57:22.377842Z","iopub.status.idle":"2022-04-09T12:57:29.030435Z","shell.execute_reply.started":"2022-04-09T12:57:22.377793Z","shell.execute_reply":"2022-04-09T12:57:29.029734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\nmodel, history = run_training(model, optimizer, scheduler,\n                              device=CONFIG['device'],\n                              num_epochs=CONFIG['epochs'])","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:57:29.034268Z","iopub.execute_input":"2022-04-09T12:57:29.034700Z","iopub.status.idle":"2022-04-09T16:44:31.614380Z","shell.execute_reply.started":"2022-04-09T12:57:29.034670Z","shell.execute_reply":"2022-04-09T16:44:31.613649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run.finish()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T16:44:31.618579Z","iopub.execute_input":"2022-04-09T16:44:31.620736Z","iopub.status.idle":"2022-04-09T16:44:35.615507Z","shell.execute_reply.started":"2022-04-09T16:44:31.620697Z","shell.execute_reply":"2022-04-09T16:44:35.614832Z"},"trusted":true},"execution_count":null,"outputs":[]}]}