{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#https://betashort-lab.com/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/kagglepytorch%E3%81%A7digit-recognizer%E3%81%AB%E6%8C%91%E6%88%A6/\n#https://www.kaggle.com/georgiisirotenko/pytorch-mnist-transferlearning-ensemble-99-714","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:15.329225Z","iopub.execute_input":"2022-01-03T04:22:15.330271Z","iopub.status.idle":"2022-01-03T04:22:16.150760Z","shell.execute_reply.started":"2022-01-03T04:22:15.330147Z","shell.execute_reply":"2022-01-03T04:22:16.149962Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"DATA_DIR=\"../input/digit-recognizer/\"","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:17.309259Z","iopub.execute_input":"2022-01-03T04:22:17.310020Z","iopub.status.idle":"2022-01-03T04:22:17.314156Z","shell.execute_reply.started":"2022-01-03T04:22:17.309980Z","shell.execute_reply":"2022-01-03T04:22:17.313070Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Data Loader**","metadata":{}},{"cell_type":"code","source":"#前処理\ntransform=transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.),std=(0.5,))\n])\n\n#データセット\nclass MyDataset(Dataset):\n    def __init__(self,features,labels,Transform):\n        self.x=features\n        self.y=labels\n        self.transform=Transform\n        \n    def __len__(self):\n        return len(self.x)\n    \n    def __getitem__(self,index):\n        return self.transform(self.x[index]), self.y[index]","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:19.448972Z","iopub.execute_input":"2022-01-03T04:22:19.449474Z","iopub.status.idle":"2022-01-03T04:22:19.456818Z","shell.execute_reply.started":"2022-01-03T04:22:19.449435Z","shell.execute_reply":"2022-01-03T04:22:19.455621Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def GetDf(df,Transform):\n    x_features=df.loc[:, df.columns !=\"label\"].values/255\n    y_labels =df.label.values\n    x_features=x_features.reshape(-1,1,28,28)\n    #x_features = np.uint8(x_features)\n    \n    x_features=torch.from_numpy(x_features)\n    y_labels=torch.from_numpy(y_labels).type(torch.LongTensor)\n    \n    return MyDataset(x_features, y_labels,Transform)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:21.318825Z","iopub.execute_input":"2022-01-03T04:22:21.319319Z","iopub.status.idle":"2022-01-03T04:22:21.324893Z","shell.execute_reply.started":"2022-01-03T04:22:21.319280Z","shell.execute_reply":"2022-01-03T04:22:21.323877Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#batch_size\nbatch_size=128\n\n\n#Prepare Dataset\ntrain_df=pd.read_csv(DATA_DIR+\"train.csv\", dtype=np.float32)\ntest_df=pd.read_csv(DATA_DIR+\"test.csv\", dtype=np.float32)\n\n\ndef create_dataloaders(df,test_size=0.2,batch_size=batch_size):\n    train_data,valid_data=train_test_split(df,test_size=test_size)\n    \n    train_dataset=GetDf(train_data,Transform=transform)\n    valid_dataset=GetDf(valid_data,Transform=transform)\n    \n    #Pytorch train and test sets\n    train_loader=torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    valid_loader=torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n    \n    return train_loader, valid_loader\n\n\ntrain_loader, valid_loader= create_dataloaders(df=train_df,test_size=0.2,batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:23.059067Z","iopub.execute_input":"2022-01-03T04:22:23.059624Z","iopub.status.idle":"2022-01-03T04:22:28.380519Z","shell.execute_reply.started":"2022-01-03T04:22:23.059587Z","shell.execute_reply":"2022-01-03T04:22:28.379694Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# **Model**","metadata":{}},{"cell_type":"code","source":"# Create CNN Model\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        \n        # Convolution 1\n        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.relu1 = nn.ReLU()\n        \n        # Max pool 1\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n        self.dropout1 = nn.Dropout(p=0.25)\n     \n        # Convolution 2\n        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0)\n        self.relu2 = nn.ReLU()\n        \n        # Max pool 2\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n        self.dropout2 = nn.Dropout(p=0.25)\n        \n        # Fully connected 1\n        self.fc1 = nn.Linear(32 * 4 * 4, 10) \n     \n    \n    def forward(self, x):\n        # Convolution 1\n        out = self.cnn1(x)\n        out = self.relu1(out)\n        \n        # Max pool 1\n        out = self.maxpool1(out)\n        out = self.dropout1(out)\n        \n        # Convolution 2 \n        out = self.cnn2(out)\n        out = self.relu2(out)\n        \n        # Max pool 2 \n        out = self.maxpool2(out)\n        out = self.dropout2(out)\n        \n        # flatten\n        out = out.view(out.size(0), -1)\n\n        # Linear function (readout)\n        out = self.fc1(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:28.785714Z","iopub.execute_input":"2022-01-03T04:22:28.785983Z","iopub.status.idle":"2022-01-03T04:22:28.797200Z","shell.execute_reply.started":"2022-01-03T04:22:28.785950Z","shell.execute_reply":"2022-01-03T04:22:28.796083Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device=\"cuda:0\"\nelse:\n    device=\"cpu\"","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:30.769189Z","iopub.execute_input":"2022-01-03T04:22:30.769905Z","iopub.status.idle":"2022-01-03T04:22:30.793478Z","shell.execute_reply.started":"2022-01-03T04:22:30.769869Z","shell.execute_reply":"2022-01-03T04:22:30.791318Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Create CNN\nmodel=CNNModel().to(device)\n\n#Cross Entropy Loss\nerror=nn.CrossEntropyLoss()\n\n#SGD Optimizer\noptimizer=torch.optim.SGD(model.parameters(), lr=0.01,weight_decay=1e-5)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:32.759013Z","iopub.execute_input":"2022-01-03T04:22:32.759675Z","iopub.status.idle":"2022-01-03T04:22:34.418182Z","shell.execute_reply.started":"2022-01-03T04:22:32.759625Z","shell.execute_reply":"2022-01-03T04:22:34.417406Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#CNN model training\ncount=0\nloss_list=[]\niteration_list=[]\naccuracy_list=[]\n\n#num_epochs=int(n_iters /(len(features_train)/batch_size))\nnum_epochs = 50\n\nfor epoch in range(num_epochs):\n    model.train()\n    for images,labels in train_loader:\n        images, labels= images.to(device), labels.to(device)\n        \n        train=Variable(images) #images.view(-1,1,28,28)\n        labels=Variable(labels)\n        \n        #Clear gradients\n        optimizer.zero_grad()\n        #Foward propagation\n        outputs=model(train)\n        #calculate softmax and loss entropy loss\n        loss=error(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        \n        count+=1\n        \n        #validation\n        if count%50==0:\n            correct=0\n            total=0\n            model.eval()\n            for images, labels in valid_loader:\n                images, labels= images.to(device), labels.to(device)\n                \n                valid=Variable(images.view(-1,1,28,28))\n                labels=Variable(labels)\n                \n                outputs=model(valid)\n                \n                #Get predictions from the maximum value\n                predicted=torch.max(outputs.data,1)[1]\n                \n                #Total number of labels\n                total +=len(labels)\n                \n                correct +=(predicted==labels).sum()\n            \n            accuracy=100*correct/ float(total)\n            \n            #store loss and iteration\n            loss_list.append(loss.data)\n            iteration_list.append(count)\n            accuracy_list.append(accuracy)\n            \n        if count%500==0:\n            #Print loss\n            print(\"Iteration: {} Loss: {} Accuracy: {} %\".format(count, loss.data, accuracy))","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:22:38.069262Z","iopub.execute_input":"2022-01-03T04:22:38.069937Z","iopub.status.idle":"2022-01-03T04:34:45.072712Z","shell.execute_reply.started":"2022-01-03T04:22:38.069900Z","shell.execute_reply":"2022-01-03T04:34:45.071950Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# visualization loss \nplt.plot(iteration_list,loss_list)\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Loss\")\nplt.title(\"CNN: Loss vs Number of iteration\")\nplt.show()\n\n# visualization accuracy \nplt.plot(iteration_list,accuracy_list,color = \"red\")\nplt.xlabel(\"Number of iteration\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"CNN: Accuracy vs Number of iteration\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:34:45.074339Z","iopub.execute_input":"2022-01-03T04:34:45.074577Z","iopub.status.idle":"2022-01-03T04:34:45.564022Z","shell.execute_reply.started":"2022-01-03T04:34:45.074541Z","shell.execute_reply":"2022-01-03T04:34:45.563358Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# **submission**","metadata":{}},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self,features,Transform):\n        self.features=features.values.reshape(-1,28,28)/255\n        self.targets=None\n        self.transform=Transform\n        \n    def __len__(self):\n        return (self.features.shape[0])\n    \n    def __getitem__(self, index):\n        return self.transform(self.features[index])","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:34:45.565367Z","iopub.execute_input":"2022-01-03T04:34:45.565612Z","iopub.status.idle":"2022-01-03T04:34:45.570850Z","shell.execute_reply.started":"2022-01-03T04:34:45.565578Z","shell.execute_reply":"2022-01-03T04:34:45.570159Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"test=TestDataset(test_df,Transform=transform)\ntest_loader = torch.utils.data.DataLoader(test,batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:34:45.572920Z","iopub.execute_input":"2022-01-03T04:34:45.573450Z","iopub.status.idle":"2022-01-03T04:34:45.609257Z","shell.execute_reply.started":"2022-01-03T04:34:45.573412Z","shell.execute_reply":"2022-01-03T04:34:45.608483Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.eval()\ntest_pred=torch.LongTensor().to(device)\nfor  data in test_loader:\n    data= Variable(data).to(device=device, dtype=torch.float)\n    output=model(data)\n    pred=output.data.max(1, keepdim=True)[1]#torch.max(outputs, 1)\n    test_pred=torch.cat((test_pred,pred),dim=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:34:45.610756Z","iopub.execute_input":"2022-01-03T04:34:45.611020Z","iopub.status.idle":"2022-01-03T04:34:49.619406Z","shell.execute_reply.started":"2022-01-03T04:34:45.610984Z","shell.execute_reply":"2022-01-03T04:34:49.618671Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_pred=test_pred.squeeze(1)\ntest_pred.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:34:49.620733Z","iopub.execute_input":"2022-01-03T04:34:49.620988Z","iopub.status.idle":"2022-01-03T04:34:49.628688Z","shell.execute_reply.started":"2022-01-03T04:34:49.620952Z","shell.execute_reply":"2022-01-03T04:34:49.628007Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame(\n    {\n        'ImageId':pd.Series(range(1,28001)),\n        \"Label\":test_pred.to('cpu').detach().numpy().copy()\n    }\n)\n\noutput.to_csv('my_submission.csv',index=False)\nprint(output.head())","metadata":{"execution":{"iopub.status.busy":"2022-01-03T04:34:49.629767Z","iopub.execute_input":"2022-01-03T04:34:49.631485Z","iopub.status.idle":"2022-01-03T04:34:49.686012Z","shell.execute_reply.started":"2022-01-03T04:34:49.631446Z","shell.execute_reply":"2022-01-03T04:34:49.685174Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#今回は使わなかったPrepare Dataset\n\ntrain=pd.read_csv(DATA_DIR+\"train.csv\", dtype=np.float32)\nfeatures_numpy=train.loc[:, train.columns !=\"label\"].values/255\ntargets_numpy=train.label.values\n\nfeatures_train, features_valid, targets_train, targets_valid=train_test_split(features_numpy, targets_numpy, test_size=0.2, random_state=42)\n\nfeatures_train=torch.from_numpy(features_train)\ntargets_train=torch.from_numpy(targets_train).type(torch.LongTensor)\nfeatures_valid = torch.from_numpy(features_valid)\ntargets_valid = torch.from_numpy(targets_valid).type(torch.LongTensor) \n\n\n\n#Pytorch train and valid sets\ntrain=torch.utils.data.TensorDataset(features_train, targets_train)\nvalid=torch.utils.data.TensorDataset(features_valid, targets_valid)\n\n#Pytorch train and valid sets\ntrain_loader=torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\nvalid_loader=torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n\n#Pytorch test sets\n\ntest=pd.read_csv(DATA_DIR+\"test.csv\").values/255\nfeatures_test=torch.from_numpy(test)\ntest=torch.utils.data.TensorDataset(features_test)\ntest_loader = torch.utils.data.DataLoader(test,batch_size=batch_size, shuffle=False)","metadata":{},"execution_count":null,"outputs":[]}]}